{
   "name": "llmforge",
   "version": "2.0.0",
   "description": "One API, every AI model, instant switching. Change from GPT-4 to Gemini to local models with a single config update. LLMForge is the lightweight, TypeScript-first solution for multi-provider AI applications with zero vendor lock-in.",
   "main": "dist/index.js",
   "module": "dist/index.mjs",
   "types": "dist/index.d.ts",
   "files": [
      "dist",
      "README.md"
   ],
   "scripts": {
      "build": "tsc && tsc -p tsconfig.esm.json",
      "test": "jest --detectOpenHandles",
      "test:watch": "jest --watch",
      "test:coverage": "jest --coverage",
      "test:openai": "jest tests/unit/openai.test.js",
      "test:gemini": "jest tests/unit/gemini.test.js",
      "test:fallback": "jest tests/integration/fallback.test.js",
      "test:validation": "jest tests/unit/validation.test.js",
      "lint": "echo \"not implemented yet\"",
      "prepare": "npm run build",
      "format": "prettier --write .",
      "format:check": "prettier --check ."
   },
   "keywords": [
      "ai",
      "llm",
      "gpt",
      "openai",
      "gemini",
      "ollama",
      "gpt",
      "chatgpt",
      "groq",
      "deepseek",
      "meta-llama",
      "qwen/qwen3-32b",
      "artificial-intelligence",
      "machine-learning",
      "orchestration",
      "multi-provider",
      "unified-api",
      "fallback",
      "typescript",
      "lightweight",
      "provider-agnostic",
      "model-switching",
      "ai-integration",
      "llm-client",
      "google-ai",
      "anthropic",
      "claude",
      "prompt",
      "completion",
      "chat",
      "generative-ai",
      "sdk",
      "wrapper",
      "abstraction",
      "runtime",
      "universal",
      "cross-provider",
      "vendor-neutral",
      "failover",
      "retry-logic",
      "token-tracking",
      "usage-monitoring",
      "local-models",
      "cloud-ai",
      "ai-orchestration",
      "model-management",
      "provider-switching",
      "intelligent-routing",
      "generative-ai",
      "genai",
      "api-client",
      "wrapper",
      "llm-gateway",
      "llm-router",
      "groq",
      "gpt-4o",
      "llama-3",
      "streaming",
      "retry",
      "chatbot",
      "nlp"
   ],
   "author": "nginH <harshanand.cloud@gmail.com>",
   "license": "MIT",
   "publishConfig": {
      "access": "public",
      "registry": "https://registry.npmjs.org/",
      "@nginH:registry": "https://npm.pkg.github.com"
   },
   "repository": {
      "type": "git",
      "url": "git+https://github.com/nginH/llmforge.git"
   },
   "bugs": {
      "url": "https://github.com/nginH/llmforge/issues"
   },
   "homepage": "https://github.com/nginH/llmforge#readme",
   "dependencies": {
      "dotenv": "^16.4.5",
      "undici": "^7.10.0",
      "undici-types": "^7.10.0"
   },
   "devDependencies": {
      "@semantic-release/changelog": "^6.0.3",
      "@semantic-release/git": "^10.0.1",
      "@semantic-release/github": "^8.1.0",
      "@semantic-release/npm": "^10.0.4",
      "@types/jest": "^29.5.12",
      "@types/node": "^20.11.24",
      "@typescript-eslint/eslint-plugin": "^7.1.0",
      "@typescript-eslint/parser": "^7.1.0",
      "eslint": "^8.57.0",
      "jest": "^29.7.0",
      "prettier": "^3.5.3",
      "semantic-release": "^21.1.1",
      "ts-jest": "^29.1.2",
      "typescript": "^5.3.3"
   }
}
